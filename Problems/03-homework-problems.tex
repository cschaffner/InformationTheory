\documentclass[a4paper,10pt,landscape,twocolumn]{scrartcl}

%% Settings
\newcommand\problemset{3}
\newcommand\deadline{Friday November 25th, 20:00h}
\newif\ifcomments
\commentsfalse % hide comments
%\commentstrue % show comments

% Packages
\usepackage[english]{exercises}
\usepackage{wasysym}
\usepackage{hyperref}
\hypersetup{colorlinks=true, urlcolor = blue, linkcolor = blue}

\usepackage{tikz}

\begin{document}

\homeworkproblems

{\sffamily\noindent
Your homework must be handed in \textbf{electronically via Moodle before \deadline}. This deadline is strict and late submissions are graded with a 0. At the end of the course, the lowest of your 6 weekly homework grades will be dropped. You are strongly encouraged to work together on the exercises, including the homework. However, after this discussion phase, you have to write down and submit your own individual solution. Numbers alone are never sufficient, always motivate your answers.
}


\begin{exercise}[Huffman Coding]
	\begin{subex}[(4pt)]
    Consider the binary source $P_X$ with $P_X(0) = \frac{1}{8}$ and $P_X(1) = \frac{7}{8}$.
    
    Design a Huffman code for $P_X$. Describe, in order, which source symbols you combine, and list the final codebook. What is the average codeword length?
	\end{subex}
\begin{subex}[(4pt)]
	Design a Huffman code for blocks of $N=2$ bits drawn from the source $P_X$. Describe, in order, which source symbols you combine, and list the final codebook. What is the average codeword length?
\end{subex}
\begin{subex}[(4pt)]
	Design a Huffman code for blocks of $N=3$ bits drawn from the source $P_X$. Describe, in order, which source symbols you combine, and list the final codebook. What is the average codeword length?
\end{subex}
\begin{subex}[(4pt)]
	For the three codes you designed ($N=1,2,3$), divide the average codeword length by $N$, and compare these values to the optimal length, i.e., $H(X)$. What do you observe?
\end{subex}
	\begin{subex}[(1pt)]
	If you were asked to design a Huffman code for a block of $N = 100$ bits, what problem would you run into?
	\end{subex}
	\begin{subex}[(2pt)]
	Consider the random variable $Z$ with
	\begin{center}
	\begin{tabular}{c | c c c c c c}
	$z$ & 1 & 2 & 3 & 4 & 5 & 6\\
	\hline
	$P_Z(z)$ & 1/10 & 3/10 & 2/10 & 2/10 & 1/10 & 1/10\\
	\end{tabular}
	\end{center}
	Design a \emph{ternary} Huffman code for $Z$ (i.e. using an alphabet with three symbols).
	\end{subex}
\end{exercise}



\begin{exercise}[Inefficiency when using the wrong code]
\begin{subex}[(2pt)]
Given are two distributions $P_X$ and $Q_X$ for the same set $\mathcal{X} = \{\mathtt{a,b,c,d}\}$:
\[
\begin{array}{c | c c c c}
x & \mathtt{a}&\mathtt{b}&\mathtt{c}&\mathtt{d}\\\hline
P_X(x) & 1/4&1/4&1/4&1/4\\
Q_X(x) & 1/2&1/4&1/8&1/8\\
\end{array}
\]
Design an optimal prefix-free code for $Q_X(x)$.
\end{subex}
\begin{subex}[(4pt)]
What is the expected codeword length of the code you just designed? (Three decimals precision)
\end{subex}
\begin{subex}[(4pt)]
What is the expected codeword length if you use this code to encode the source $P_X$? (Three decimals precision)
\end{subex}
\begin{subex}[(4pt)]
Show that in general, when using optimal code for any source source $Q_X$ (which has lengths $\ell(x) = \lceil -\log Q_X(x) \rceil$ for all $x \in \mathcal{X}$) to encode another source $P_X$, this incurs a penalty of $D(P_X||Q_X)$ in the average description length.

More formally, prove that
\[
H(P_X) + D(P_X||Q_X) \leq \mathbb{E}_{P_X}[\ell(X)] \leq H(P_X) + D(P_X||Q_X) + 1
\]
for all $P_X$ and $Q_X$.
\end{subex}
\end{exercise}




\begin{exercise}[Shannon code (6pt)]
Consider the following method for generating a code for a random variable $X$ which takes on $m$ values $\{1,2,...,m\}$. Assume that the probabilities are ordered such that $P_X(1) \geq P_X(2) \geq ... \geq P_X(m)$. Define
\[
F_i := \sum_{k=1}^{i-1} P_X(k),
\]
the sum of the probabilities of all symbols less than $i$. Then the Shannon code is defined by assigning the (binary representation of the) number $F_i \in [0,1]$ as the codeword for $i$, where $F_i$ is rounded off to $\lceil \log\frac{1}{P_X(i)}\rceil$ bits.
	\begin{subex}[(1pt)]
	Construct the code for the probability distribution $P_X(1) = \frac{1}{2}$, $P_X(2) = \frac{1}{4}$, $P_X(3) = P_X(4) = \frac{1}{8}$
	\end{subex}
	\begin{subex}[(1pt)]
	Construct the code for the probability distribution $P_Y(1) = P_Y(2) = P_Y(3) = \frac{1}{3}$.
	\end{subex}
	\begin{subex}[(2pt)]
	Show that the Shannon code is prefix-free.
	\end{subex}
	\begin{subex}[(2pt)]
	Show that the average length $\ell_S$ of the Shannon code satisfies
	\[
	H(X) \leq \ell_S(P_X) < H(X) + 1.
	\]
	\end{subex}
\end{exercise}


\begin{exercise}[Programming project (10pt)]
Invent a compressor and uncompressor for a source file of $N=10000$
bits each having probability $p=0.01$ of being a $1$. Implement them
and estimate how well your method works.

Evaluate the performance of your algorithm on \href{https://github.com/cschaffner/InformationTheory/raw/master/Problems/random01.txt}{this particular
  file}. Use \href{https://repl.it/@ChrisSchaffner/RandomFile}{this program} to generate more testdata.
\end{exercise}



\end{document}