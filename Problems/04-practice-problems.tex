\documentclass[a4paper,10pt,landscape,twocolumn]{scrartcl}

%% Settings
\newcommand\problemset{4}
\newcommand\deadline{Friday November 18th, 20:00h}
\newif\ifcomments
\commentsfalse % hide comments
%\commentstrue % show comments

% Packages
\usepackage[english]{exercises}
\usepackage{wasysym}
\usepackage{hyperref}
\hypersetup{colorlinks=true, urlcolor = blue, linkcolor = blue}

\begin{document}

\practiceproblems

{\sffamily\noindent
This week's exercises deal with entropy diagrams and stochastic processes. You do not have to hand in these exercises, they are for practicing only. Problems marked with a $\bigstar$ are generally a bit harder. If you have questions about any of the exercises, please post them in the \href{https://www.moodle.ch/lms/mod/forum/view.php?id=2219}{discussion forum on Moodle}, and try to help each other. We will also keep an eye on the forum.
}

\begin{exercise}[Entropy diagram]
Show that the value
\[
R(X;Y;Z) = I(X;Y) - I(X;Y|Z)
\]
is invariant under permutations of its arguments.
\end{exercise}

\begin{exercise}[]
For each statement below, specify a joint distribution $P_{XYZ}$ of random variables $X$, $Y$, and $Z$ ($P_{XY}$ of $X$ and $Y$ in (a)) such that the following inequalities hold.
\begin{subex}
There exists a $y$ such that $H(X|Y=y) > H(X)$.
\end{subex}
\begin{subex}
$I(X;Y) > I(X;Y|Z)$
\end{subex}
\begin{subex}
$I(X;Y) < I(X;Y|Z)$
\end{subex}
\textbf{Note:} the distributions have to be different from the examples from the lecture or the lecture notes.
\end{exercise}

\begin{exercise}[Conditional mutual information]
Consider a sequence of $n$ binary random variables $X_1, X_2, ..., X_n$.
Each sequence with an even number of 1's has probability $2^{-(n-1)}$ and each sequence with an odd number
of 1's has probability 0. Find the mutual informations
\[
I(X_1;X_2), I(X_2;X_3|X_1), ..., I(X_{n-1};X_n|X_1, ..., X_{n-2}).
\]
\end{exercise}
\vspace{-0.5cm}
\begin{exercise}[Markov chains with 4 random variables]
Let $W \rightarrow X \rightarrow Y \rightarrow Z$ be a Markov chain with 4 RVs, i.e.,\ it holds that $P_{Z|YXW} = P_{Z|Y}$ and $W \leftrightarrow X \leftrightarrow Y$ is a Markov chain with three random variables as defined in the lecture.
\begin{subex}
	Show that $X \leftrightarrow Y \leftrightarrow Z$ is a Markov chain.
\end{subex}
\begin{subex}
Show that $W \leftrightarrow (X,Y) \leftrightarrow Z$ is a Markov chain with three random variables $W, (XY), Z$.
\end{subex}
\begin{subex}
Show that $Z \rightarrow Y \rightarrow X \rightarrow W$. Therefore, it is also justified to write $W \leftrightarrow X \leftrightarrow Y \leftrightarrow Z$, as in the case for three RVs.
\end{subex}
\begin{subex**}
Can you generalize the two properties above to Markov chains of $n>4$ random variables?
\end{subex**}
\end{exercise}

% \begin{exercise}[Bernoulli process]
% Let $X_1, X_2, ...$ be distributed according to the Bernoulli$(p)$ distribution. Consider the associated Markov chain $\{Y_i\}_{i=1}^n$, where $Y_i$ is the number of 1's in the current run of 1's. For example, if $X^n = 101110...$, then $Y^n = 101230....$.
% \begin{subex}
% Find the entropy rate of $X^n$.
% \end{subex}
% \begin{subex}
% Find the entropy rate of $Y^n$
% \end{subex}
% \end{exercise}



\begin{exercise}[Ces\'{a}ro mean]
Show that if $a_n \to a$ and $b_n = \frac{1}{n}\sum_{i=1}^n a_i$, then $b_n \to a$. This is Theorem~4.2.3 in Cover \& Thomas.
\end{exercise}



\begin{exercise}[Stationary processes] Let $..., X_{-1}, X_0, X_1, ...$ be a stationary (not necessarily Markov) stochastic process. Recall that this means that for any $n \in \mathbb{N}$ and $k \in \mathbb{Z}$, it holds that $P_{X_1 \ldots X_n} = P_{X_{1+k},\ldots,X_{n+k}}$. Which of the following statements are true? Prove or provide a counterexample.
\begin{subex}
$H(X_n|X_0) = H(X_{-n}|X_0)$
\end{subex}
\begin{subex}
$H(X_n|X_0) \geq H(X_{n-1}|X_0)$
\end{subex}
\begin{subex}
$H(X_n|X_1, X_2, ..., X_{n-1}, X_{n+1})$ is nonincreasing in $n$.
\end{subex}
\begin{subex}
$H(X_n|X_1, X_2, ..., X_{n-1}, X_{n+1}, ..., X_{2n})$ is nonincreasing in $n$.
\end{subex}
\end{exercise}


% \begin{exercise}[Branching process]
% A random process repeatedly flips a fair coin to choose between the two words \texttt{ab} and \texttt{abc}. A typical sample from this process is
% \[
% \mathtt{a b c a b c a b a b a b c a b c a b c a b c a b c a b a b a b c a b a b a b c a b c ...}
% \]
% Let $X_i$ denote the letter at the $i$th position.
% \begin{subex}
% Draw the transition diagram for the process $X_1, X_2, X_3, ...$.
% \end{subex}
% \begin{subex}
% Is this process stationary?
% \end{subex}
% \begin{subex}
% Compute the entropy rate of this process.
% \end{subex}
% \end{exercise}












\end{document}