\documentclass[a4paper,10pt,landscape,twocolumn]{scrartcl}

%% Settings
\newcommand\problemset{5}
\newcommand\deadline{Friday November 18th, 20:00h}
\newif\ifcomments
\commentsfalse % hide comments
%\commentstrue % show comments

% Packages
\usepackage[english]{exercises}
\usepackage{wasysym}
\usepackage{hyperref}
\hypersetup{colorlinks=true, urlcolor = blue, linkcolor = blue}

\begin{document}

\practiceproblems

{\sffamily\noindent
This week's exercises deal with random processes. \practiceinstructions
}

\begin{exercise}[Markov chains with 4 random variables]
Let $W \rightarrow X \rightarrow Y \rightarrow Z$ be a Markov chain with 4 RVs, i.e.,\ it holds that $P_{Z|YXW} = P_{Z|Y}$ and $W \leftrightarrow X \leftrightarrow Y$ is a Markov chain with three random variables as defined in the lecture.
\begin{subex}
	Show that $X \leftrightarrow Y \leftrightarrow Z$ is a Markov chain.
\end{subex}
\begin{subex}
Show that $W \leftrightarrow (X,Y) \leftrightarrow Z$ is a Markov chain with three random variables $W, (XY), Z$.
\end{subex}
\begin{subex}
Show that $Z \rightarrow Y \rightarrow X \rightarrow W$. Therefore, it is also justified to write $W \leftrightarrow X \leftrightarrow Y \leftrightarrow Z$, as in the case for three RVs.
\end{subex}
\begin{subex**}
Can you generalize the two properties above to Markov chains of $n>4$ random variables?
\end{subex**}
\end{exercise}

% \begin{exercise}[Bernoulli process]
% Let $X_1, X_2, ...$ be distributed according to the Bernoulli$(p)$ distribution. Consider the associated Markov chain $\{Y_i\}_{i=1}^n$, where $Y_i$ is the number of 1's in the current run of 1's. For example, if $X^n = 101110...$, then $Y^n = 101230....$.
% \begin{subex}
% Find the entropy rate of $X^n$.
% \end{subex}
% \begin{subex}
% Find the entropy rate of $Y^n$
% \end{subex}
% \end{exercise}



\begin{exercise}[Ces\'{a}ro mean]
Show that if $a_n \to a$ and $b_n = \frac{1}{n}\sum_{i=1}^n a_i$, then $b_n \to a$. This is Theorem~4.2.3 in Cover \& Thomas.
\end{exercise}



\begin{exercise}[Stationary processes] Let $..., X_{-1}, X_0, X_1, ...$ be a stationary (not necessarily Markov) stochastic process. Recall that this means that for any $n \in \mathbb{N}$ and $k \in \mathbb{Z}$, it holds that $P_{X_1 \ldots X_n} = P_{X_{1+k},\ldots,X_{n+k}}$. Which of the following statements are true? Prove or provide a counterexample.
\begin{subex}
$H(X_n|X_0) = H(X_{-n}|X_0)$
\end{subex}
\begin{subex}
$H(X_n|X_0) \geq H(X_{n-1}|X_0)$
\end{subex}
\begin{subex}
$H(X_n|X_1, X_2, ..., X_{n-1}, X_{n+1})$ is nonincreasing in $n$.
\end{subex}
\begin{subex}
$H(X_n|X_1, X_2, ..., X_{n-1}, X_{n+1}, ..., X_{2n})$ is nonincreasing in $n$.
\end{subex}
\end{exercise}


% \begin{exercise}[Branching process]
% A random process repeatedly flips a fair coin to choose between the two words \texttt{ab} and \texttt{abc}. A typical sample from this process is
% \[
% \mathtt{a b c a b c a b a b a b c a b c a b c a b c a b c a b a b a b c a b a b a b c a b c ...}
% \]
% Let $X_i$ denote the letter at the $i$th position.
% \begin{subex}
% Draw the transition diagram for the process $X_1, X_2, X_3, ...$.
% \end{subex}
% \begin{subex}
% Is this process stationary?
% \end{subex}
% \begin{subex}
% Compute the entropy rate of this process.
% \end{subex}
% \end{exercise}









\begin{exercise}[Random walk on a chessboard]
Consider a 3x3 chessboard. We place a knight (who can move 2 spaces horizontally and 1 vertically or 1 space horizontally and 2 vertically) in the top left corner, and let him perform a random walk on this chessboard, choosing his move uniformly random every time. What is the entropy rate of this process?
\end{exercise}




\end{document}