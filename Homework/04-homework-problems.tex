\documentclass[a4paper,10pt,landscape,twocolumn]{scrartcl}

%% Settings
\newcommand\problemset{4}
\newcommand\deadline{Friday December 2nd, 20:00h}
\newif\ifcomments
\commentsfalse % hide comments
%\commentstrue % show comments

% Packages
\usepackage[english]{exercises}
\usepackage{wasysym}
\usepackage{hyperref}
\hypersetup{colorlinks=true, urlcolor = blue, linkcolor = blue}

\usepackage{tikz}

\begin{document}

\homeworkproblems

{\sffamily\noindent
Your homework must be handed in \textbf{electronically via Moodle before \deadline}. This deadline is strict and late submissions are graded with a 0. At the end of the course, the lowest of your 6 weekly homework grades will be dropped. You are strongly encouraged to work together on the exercises, including the homework. However, after this discussion phase, you have to write down and submit your own individual solution. Numbers alone are never sufficient, always motivate your answers.
}


\begin{exercise}[Bottleneck (4pt)]
Suppose a Markov chain starts in one of $n$ states, necks down to $k < n$ states, and then fans back to $m > k$ states. Thus $X_1 \to X_2 \to X_3$, with $\mathcal{X}_1 = \{1, 2, ..., n\}$, $\mathcal{X}_2 = \{1, 2, ..., k\}$, and $\mathcal{X}_3 = \{1, 2, ..., m\}$.
\begin{subex}[(3pt)]
Show that the dependence of $X_1$ and $X_3$ is limited by the bottleneck by proving that $I(X_1;X_2) \leq \log k$.
\end{subex}
\begin{subex}[(1pt)]
Evaluate $I(X_1;X_3)$ for $k = 1$, and conclude that no dependence can survive such a bottleneck.
\end{subex}
\end{exercise}






\begin{exercise}[A dog looking for a bone (6pt)]
A dog walks on the integers, possibly reversing direction at each step with probability $p = 0.1$. Let $X_0 = 0$. The first step is equally likely to be positive or negative. A typical walk might look like this:
\[
(X_0, X_1, ...) = (0, -1, -2, -3, -4, -3, -2, -1, 0, 1, ...).
\]
	\begin{subex}[(2pt)]
	What is the expected number of steps the dog takes in one direction, before reversing?
	\end{subex}
	\begin{subex}[(1pt)]
	Is this a Markov process? If so, is it time-invariant?
	\end{subex}
	\begin{subex}[(3pt)]
	Find the entropy rate of this browsing dog.
	\end{subex}
\end{exercise}

\begin{exercise}[Run-length coding (3pt)]
Let $X_1, X_2, ..., X_n$ be (possibly dependent) binary random variables.
Suppose one calculates the run lengths $R = (R_1, R_2, ...)$ of this sequence (in order as they occur).
For example, the sequence $X = 0001100100$ yields run lengths $R = (3, 2, 2, 1, 2)$. Compare
$H(X_1, X_2, . . . , X_n)$, $H(R)$ and $H(X_n, R)$. Show all equalities and inequalities, and bound all the
differences.
\end{exercise}

\begin{exercise}[Entropy rates of Markov chains (10pt)]
	\begin{subex}[(2pt)]
	Find the entropy rate of the two-state Markov chain with transition matrix
	\[
	P = \left[
	\begin{array}{c c}
	1-p_{ab} & p_{ab}\\
	p_{ba} & 1 - p_{ba}
	\end{array}
	\right].
	\]
	\end{subex}
	\begin{subex}[(1pt)]
	Find values of $p_{ab}$ and $p_{ba}$ that maximize the entropy rate of part (a).
	\end{subex}
	\begin{subex}[(1pt)]
	Find the entropy rate of the two-state Markov chain with transition matrix
	\[
	P = \left[
	\begin{array}{c c}
	1-p & p\\
	1 & 0
	\end{array}
	\right].
	\]
	\end{subex}
	\begin{subex}[(2pt)]
	Find the maximum value of the entropy rate of for part (c). \\\textbf{Hint:} we expect that the maximizing value of $p$ should be less than 1/2, since the 0 state permits more information to be generated than the 1 state. This allows you to discard one possible solution.
	\end{subex}
	\begin{subex}[(4pt)]
	Let $N(t)$ be the number of allowable state sequences of length $t$ for the Markov chain of part (c). Find $N(t)$ and calculate
	\[
	H_0 := \lim_{t \to \infty} \frac{1}{t} \log N(t).
	\]
	Why is $H_0$ an upper bound on the entropy rate of the Markov chain? Compare $H_0$ with the maximum entropy found in (d).
	\\\textbf{Hint:} Find $N(0)$ and $N(1)$, and find a linear recurrence that expresses $N(t)$ in terms of $N(t-1)$ and $N(t-2)$. What well-known sequence does this remind you of?
	\end{subex}
\end{exercise}







\end{document}